{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68c6d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def estimate_point_density(pcd, radius_mm=1.0, min_neighbors=30, verbose=False):\n",
    "    kdtree = o3d.geometry.KDTreeFlann(pcd)\n",
    "    counts = []\n",
    "    total_checked = 0\n",
    "    for i in range(0, len(pcd.points), max(1, len(pcd.points)//1000)):  # sample ~1000 points\n",
    "        [_, idx, _] = kdtree.search_radius_vector_3d(pcd.points[i], radius_mm)\n",
    "        neighbor_count = len(idx) - 1  # exclude the point itself\n",
    "        if neighbor_count >= min_neighbors:\n",
    "            counts.append(neighbor_count)\n",
    "        total_checked += 1\n",
    "\n",
    "    if counts:\n",
    "        avg_density = np.mean(counts)\n",
    "        if verbose:\n",
    "            print(f\"[INFO] Average density (excluding sparse points): {avg_density:.2f} points per {radius_mm}mm sphere\")\n",
    "            print(f\"[INFO] Used {len(counts)} / {total_checked} sampled points (â‰¥ {min_neighbors} neighbors)\")\n",
    "    else:\n",
    "        avg_density = 0\n",
    "        print(f\"[WARN] No sampled points had â‰¥ {min_neighbors} neighbors.\")\n",
    "\n",
    "    return avg_density\n",
    "\n",
    "def raycast_topdown(mesh, x_rotation, y_rotation, z_rotation, spacing=0.1):\n",
    "\n",
    "    Rx = mesh.get_rotation_matrix_from_axis_angle([np.deg2rad(x_rotation), 0, 0])\n",
    "    Ry = mesh.get_rotation_matrix_from_axis_angle([0, np.deg2rad(y_rotation), 0])\n",
    "    Rz = mesh.get_rotation_matrix_from_axis_angle([0, 0, np.deg2rad(z_rotation)])\n",
    "    mesh.rotate(Rx, center=mesh.get_center())\n",
    "    mesh.rotate(Ry, center=mesh.get_center())\n",
    "    mesh.rotate(Rz, center=mesh.get_center())\n",
    "\n",
    "    scene = o3d.t.geometry.RaycastingScene()\n",
    "    t_mesh = o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n",
    "    _ = scene.add_triangles(t_mesh)\n",
    "    aabb = mesh.get_axis_aligned_bounding_box()\n",
    "    min_x, min_y, _ = aabb.min_bound\n",
    "    max_x, max_y, _ = aabb.max_bound\n",
    "    x_vals = np.linspace(min_x, max_x, int((max_x - min_x)/spacing))\n",
    "    y_vals = np.linspace(min_y, max_y, int((max_y - min_y)/spacing))\n",
    "    xx, yy = np.meshgrid(x_vals, y_vals)\n",
    "    origin_z = aabb.max_bound[2] + 10\n",
    "    origins = np.stack([xx.ravel(), yy.ravel(), np.full(xx.size, origin_z)], axis=1)\n",
    "    directions = np.tile([0, 0, -1], (len(origins), 1))\n",
    "    rays = o3d.core.Tensor(np.hstack((origins, directions)), dtype=o3d.core.Dtype.Float32)\n",
    "    hits = scene.cast_rays(rays)\n",
    "    mask = hits['t_hit'].isfinite()\n",
    "    hit_points = origins[mask.numpy()] + hits['t_hit'][mask].numpy().reshape(-1, 1) * directions[mask.numpy()]\n",
    "    return o3d.geometry.PointCloud(o3d.utility.Vector3dVector(hit_points))\n",
    "\n",
    "def preprocess_for_fpfh(pcd, voxel_size):\n",
    "    \"\"\"Downsample and estimate FPFH features for a point cloud.\"\"\"\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    pcd_down.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2, max_nn=30)\n",
    "    )\n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=100)\n",
    "    )\n",
    "    return pcd_down, fpfh\n",
    "\n",
    "def run_global_icp_alignment(scan_pcd, cad_pcd, voxel_size=1.0, verbose=False):\n",
    "    \"\"\"Run global RANSAC + ICP refinement.\"\"\"\n",
    "    scan_down, scan_fpfh = preprocess_for_fpfh(scan_pcd, voxel_size)\n",
    "    cad_down, cad_fpfh = preprocess_for_fpfh(cad_pcd, voxel_size)\n",
    "\n",
    "    # RANSAC-based global registration\n",
    "    result_ransac = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        cad_down, scan_down, cad_fpfh, scan_fpfh, mutual_filter=True,\n",
    "        max_correspondence_distance=voxel_size * 1.5,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        ransac_n=4,\n",
    "        checkers=[\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(voxel_size * 1.5)\n",
    "        ],\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "    )\n",
    "\n",
    "    eval_ransac = o3d.pipelines.registration.evaluate_registration(\n",
    "        cad_down, scan_down, max_correspondence_distance=voxel_size * 1.5,\n",
    "        transformation=result_ransac.transformation\n",
    "    )\n",
    "    print(f\"[INFO] RANSAC Alignment RMSE: {eval_ransac.inlier_rmse:.4f} | Fitness: {eval_ransac.fitness:.4f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"[INFO] Global RANSAC transformation:\")\n",
    "        print(result_ransac.transformation)\n",
    "\n",
    "    scan_pcd.estimate_normals()\n",
    "    cad_pcd.estimate_normals()\n",
    "\n",
    "    result_icp = o3d.pipelines.registration.registration_icp(\n",
    "        cad_pcd, scan_pcd, 2.0, result_ransac.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    )\n",
    "\n",
    "    # Evaluate ICP result\n",
    "    eval_icp = o3d.pipelines.registration.evaluate_registration(\n",
    "        cad_pcd, scan_pcd, max_correspondence_distance=2.0,\n",
    "        transformation=result_icp.transformation\n",
    "    )\n",
    "    print(f\"[INFO] ICP Alignment RMSE: {eval_icp.inlier_rmse:.4f} | Fitness: {eval_icp.fitness:.4f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"[INFO] ICP refinement transformation:\")\n",
    "        print(result_icp.transformation)\n",
    "        print(f\"[INFO] ICP Fitness: {result_icp.fitness:.4f}, RMSE: {result_icp.inlier_rmse:.4f}\")\n",
    "\n",
    "    return result_icp.transformation\n",
    "\n",
    "def run_fpfh_ransac_only(scan_pcd, cad_pcd, voxel_size=1.0, verbose=False):\n",
    "    \"\"\"Run global FPFH-based RANSAC registration only (no ICP refinement).\"\"\"\n",
    "    scan_down, scan_fpfh = preprocess_for_fpfh(scan_pcd, voxel_size)\n",
    "    cad_down, cad_fpfh = preprocess_for_fpfh(cad_pcd, voxel_size)\n",
    "\n",
    "    result_ransac = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        cad_down, scan_down, cad_fpfh, scan_fpfh, mutual_filter=True,\n",
    "        max_correspondence_distance=voxel_size * 1.5,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        ransac_n=4,\n",
    "        checkers=[\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(voxel_size * 1.5)\n",
    "        ],\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"[INFO] Global RANSAC transformation (FPFH only):\")\n",
    "        print(result_ransac.transformation)\n",
    "        print(f\"[INFO] Fitness: {result_ransac.fitness:.4f}, RMSE: {result_ransac.inlier_rmse:.4f}\")\n",
    "\n",
    "    return result_ransac.transformation, result_ransac\n",
    "\n",
    "def run_centered_icp_sweep(source, target, thresholds, method='point_to_point', verbose=False):\n",
    "    \"\"\"\n",
    "    Run ICP alignment between source and target using center-to-center translation as initial guess.\n",
    "    Evaluate ICP over a list of thresholds and return the best transformation and evaluation table.\n",
    "    \"\"\"\n",
    "    trans_init = np.eye(4)\n",
    "\n",
    "    if method == 'point_to_point':\n",
    "        estimation = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    elif method == 'point_to_plane':\n",
    "        source.estimate_normals()\n",
    "        target.estimate_normals()\n",
    "        estimation = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Use 'point_to_point' or 'point_to_plane'.\")\n",
    "\n",
    "    results = []\n",
    "    for threshold in tqdm(thresholds, desc=\"Evaluating ICP thresholds\"):\n",
    "        reg_result = o3d.pipelines.registration.registration_icp(\n",
    "            source, target, threshold, trans_init, estimation)\n",
    "        \n",
    "        evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "            source, target, threshold, reg_result.transformation)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Threshold: {threshold:.3f}\")\n",
    "            print(f\"ICP Fitness: {reg_result.fitness:.4f}, RMSE: {reg_result.inlier_rmse:.4f}\")\n",
    "            print(f\"Eval Fitness: {evaluation.fitness:.4f}, Eval RMSE: {evaluation.inlier_rmse:.4f}\")\n",
    "            print(f\"Transformation:\\n{reg_result.transformation}\\n{'-' * 40}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Threshold\": threshold,\n",
    "            \"RMSE\": evaluation.inlier_rmse,\n",
    "            \"Fitness\": evaluation.fitness,\n",
    "            \"Transformation\": reg_result.transformation\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    best_idx = df[\"RMSE\"].idxmin()\n",
    "    best_result = df.loc[best_idx]\n",
    "\n",
    "    return best_result, df\n",
    "\n",
    "def crop_scan_near_mesh(scan_pcd, cad_mesh, max_distance=2.5):\n",
    "\n",
    "    t_mesh = o3d.t.geometry.TriangleMesh.from_legacy(cad_mesh)\n",
    "    scene = o3d.t.geometry.RaycastingScene()\n",
    "    _ = scene.add_triangles(t_mesh)\n",
    "\n",
    "    scan_pts = np.asarray(scan_pcd.points)\n",
    "    pcd_tensor = o3d.core.Tensor(scan_pts, dtype=o3d.core.Dtype.Float32)\n",
    "\n",
    "    signed_dists = scene.compute_signed_distance(pcd_tensor)\n",
    "    #abs_dists = np.abs(signed_dists.numpy())\n",
    "    sd = signed_dists.numpy()\n",
    "    mask = (sd < 0) | ((sd >= 0) & (sd < max_distance))\n",
    "\n",
    "    cropped = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(scan_pts[mask]))\n",
    "    return cropped\n",
    "\n",
    "def remove_outliers(pcd, nb_neighbors=20, std_ratio=2.0, radius=1.5, min_points=10):\n",
    "    pcd_clean, ind_stat = pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "    pcd_clean, ind_rad = pcd_clean.remove_radius_outlier(nb_points=min_points, radius=radius)\n",
    "    \n",
    "    return pcd_clean\n",
    "\n",
    "def remove_outliers2(pcd, nb_neighbors=20, std_ratio=2.0, radius=1.5, min_points=10):\n",
    "    # Step 1: Statistical outlier removal\n",
    "    _, ind_stat = pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "    \n",
    "    # Apply SOR inliers to get cleaned PCD\n",
    "    pcd_stat = pcd.select_by_index(ind_stat)\n",
    "\n",
    "    # Step 2: Radius outlier removal\n",
    "    _, ind_rad = pcd_stat.remove_radius_outlier(nb_points=min_points, radius=radius)\n",
    "\n",
    "    # Get final cleaned PCD\n",
    "    pcd_clean = pcd_stat.select_by_index(ind_rad)\n",
    "\n",
    "    # Determine final inlier indices relative to original point cloud\n",
    "    ind_final = np.asarray(ind_stat)[ind_rad]\n",
    "    ind_outliers = np.setdiff1d(np.arange(len(pcd.points)), ind_final)\n",
    "\n",
    "    return pcd_clean, ind_final, ind_outliers\n",
    "\n",
    "def dbscan_cleanup(pcd, eps=1.5, min_points=15):\n",
    "    labels = np.array(pcd.cluster_dbscan(eps=eps, min_points=min_points))\n",
    "    largest_cluster = labels == np.bincount(labels[labels >= 0]).argmax()\n",
    "    final = pcd.select_by_index(np.where(largest_cluster)[0])\n",
    "    return final\n",
    "\n",
    "def preProcessData(scan_pcd, cad_mesh, x_rotation, y_rotation, z_rotation, verbose=False):\n",
    "    o3d.visualization.draw_geometries([scan_pcd])\n",
    "    avg_density = estimate_point_density(scan_pcd, radius_mm=1.0, verbose=verbose)\n",
    "    cad_pcd = raycast_topdown(cad_mesh, x_rotation=x_rotation, y_rotation=y_rotation, z_rotation=z_rotation, spacing=0.1)\n",
    "    o3d.visualization.draw_geometries([cad_pcd])\n",
    "    T_final = run_global_icp_alignment(scan_pcd, cad_pcd, voxel_size=1.0, verbose=verbose)\n",
    "    #cad_pcd_center = np.mean(np.asarray(cad_pcd.points), axis=0)\n",
    "    #scan_pcd_center = np.mean(np.asarray(scan_pcd.points), axis=0)\n",
    "\n",
    "    # Compute the translation vector\n",
    "    #translation = cad_pcd_center - scan_pcd_center\n",
    "\n",
    "    # Translate the hull_pcd to align the centers\n",
    "    #scan_pcd.points = o3d.utility.Vector3dVector(np.asarray(scan_pcd.points) + translation)\n",
    "    #T_fpfh, result = run_fpfh_ransac_only(scan_pcd, cad_pcd, voxel_size=1.0, verbose=True)\n",
    "    # thresholds = np.linspace(1, 150, 25)\n",
    "    # best_result, table = run_centered_icp_sweep(scan_pcd, cad_pcd, thresholds, method='point_to_point', verbose=True)\n",
    "    # ðŸ“Š Display table\n",
    "    # print(\"\\n=== ICP Sweep Results ===\")\n",
    "    # print(table[[\"Threshold\", \"RMSE\", \"Fitness\"]].to_string(index=False))\n",
    "    # print(\"\\nBest result:\")\n",
    "    # print(f\"Threshold: {best_result['Threshold']:.3f}\")\n",
    "    # print(f\"RMSE: {best_result['RMSE']:.4f}\")\n",
    "    # print(f\"Fitness: {best_result['Fitness']:.4f}\")\n",
    "    cad_pcd.paint_uniform_color([0,1,0])\n",
    "    scan_pcd.paint_uniform_color([1,0,0])\n",
    "    cad_pcd.transform(T_final)\n",
    "    cad_mesh.transform(T_final)\n",
    "    # cad_pcd.transform(T_final)\n",
    "    # cad_mesh.transform(T_final)\n",
    "    o3d.visualization.draw_geometries([scan_pcd, cad_pcd])\n",
    "    cropped = crop_scan_near_mesh(scan_pcd, cad_mesh, max_distance=1.5)\n",
    "    cropped.paint_uniform_color([0.2, 0.35, 0.8])  # Blue for cropped points\n",
    "    cleaned = remove_outliers(cropped, nb_neighbors=20, std_ratio=4.0, radius=2.5, min_points=8)\n",
    "    o3d.visualization.draw_geometries([cleaned])\n",
    "    preprocessed_pcd = dbscan_cleanup(cleaned, eps=0.6, min_points=15)\n",
    "    o3d.visualization.draw_geometries([preprocessed_pcd])\n",
    "    nn_distance = np.mean([preprocessed_pcd.compute_nearest_neighbor_distance()])\n",
    "    radius_normals = nn_distance*4\n",
    "    preprocessed_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normals, max_nn=16), fast_normal_computation=True)\n",
    "    return preprocessed_pcd, avg_density, cad_pcd\n",
    "\n",
    "def visualize_fpfh_alignment(scan_pcd, cad_mesh, x_rotation, y_rotation, z_rotation, voxel_size=1, vis_voxel_size=0.1, verbose=False):\n",
    "    # Step 1: Create CAD point cloud via raycasting and downsample both for visualization\n",
    "    cad_pcd_raw = raycast_topdown(cad_mesh, x_rotation, y_rotation, z_rotation, spacing=0.1)\n",
    "    # scan_vis = scan_pcd.voxel_down_sample(vis_voxel_size)\n",
    "    # cad_vis = cad_pcd_raw.voxel_down_sample(vis_voxel_size)\n",
    "\n",
    "    # # Step 2: Move both to origin\n",
    "    # scan_center = scan_vis.get_center()\n",
    "    # cad_center = cad_vis.get_center()\n",
    "    # scan_vis.translate(-scan_center)\n",
    "    # cad_vis.translate(-cad_center)\n",
    "\n",
    "    # # Step 3: Offset CAD for separation\n",
    "    # scan_bbox = scan_vis.get_axis_aligned_bounding_box()\n",
    "    # cad_bbox = cad_vis.get_axis_aligned_bounding_box()\n",
    "    # x_offset = scan_bbox.get_extent()[0] + 0.5 * cad_bbox.get_extent()[0]\n",
    "    # cad_vis_pre = cad_vis.translate([x_offset-20, 0, -40], relative=False)\n",
    "\n",
    "    # Step 4: Color and show pre-alignment\n",
    "    # scan_vis.paint_uniform_color([1, 0, 0])  # Red\n",
    "    # cad_vis_pre.paint_uniform_color([0, 1, 0])  # Green\n",
    "    # o3d.visualization.draw_geometries([scan_vis, cad_vis_pre], window_name=\"Before FPFH RANSAC Alignment\")\n",
    "\n",
    "    # Step 5: Perform real alignment using full-resolution data\n",
    "    scan_down, scan_fpfh = preprocess_for_fpfh(scan_pcd, voxel_size)\n",
    "    cad_down, cad_fpfh = preprocess_for_fpfh(cad_pcd_raw, voxel_size)\n",
    "\n",
    "    result_ransac = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        cad_down, scan_down, cad_fpfh, scan_fpfh, mutual_filter=True,\n",
    "        max_correspondence_distance=voxel_size * 1.5,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        ransac_n=4,\n",
    "        checkers=[\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(voxel_size * 1.5)\n",
    "        ],\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "    )\n",
    "\n",
    "    # Step 6: Apply transformation to full-res CAD and downsample for visualization\n",
    "    cad_aligned_vis = cad_pcd_raw.transform(result_ransac.transformation).voxel_down_sample(vis_voxel_size)\n",
    "    scan_pcd.paint_uniform_color([1, 0, 0])\n",
    "    cad_aligned_vis.paint_uniform_color([0, 1, 0])\n",
    "    o3d.visualization.draw_geometries([scan_pcd, cad_aligned_vis], window_name=\"After FPFH RANSAC Alignment\")\n",
    "\n",
    "    return result_ransac.transformation\n",
    "\n",
    "def visualize_outlier_removal(scan_pcd, cad_mesh, x_rotation, y_rotation, z_rotation, voxel_size=1, vis_voxel_size=0.1, verbose=False):\n",
    "    #o3d.visualization.draw_geometries([scan_pcd])\n",
    "    #avg_density = estimate_point_density(scan_pcd, radius_mm=1.0, verbose=verbose)\n",
    "    cad_pcd = raycast_topdown(cad_mesh, x_rotation=x_rotation, y_rotation=y_rotation, z_rotation=z_rotation, spacing=0.1)\n",
    "    #o3d.visualization.draw_geometries([cad_pcd])\n",
    "    T_final = run_global_icp_alignment(scan_pcd, cad_pcd, voxel_size=1.0, verbose=verbose)\n",
    "    cad_pcd.paint_uniform_color([0,1,0])\n",
    "    scan_pcd.paint_uniform_color([1,0,0])\n",
    "    cad_pcd.transform(T_final)\n",
    "    cad_mesh.transform(T_final)\n",
    "    #o3d.visualization.draw_geometries([scan_pcd, cad_pcd])\n",
    "    cropped = crop_scan_near_mesh(scan_pcd, cad_mesh, max_distance=1.5)\n",
    "    cropped.paint_uniform_color([0.2, 0.35, 0.8])  # Blue for cropped points\n",
    "    cleaned, inlier_indices, outlier_indices = remove_outliers2(cropped, nb_neighbors=20, std_ratio=4.0, radius=2.5, min_points=8)\n",
    "\n",
    "    # Select subsets\n",
    "    inlier_pcd = cropped.select_by_index(inlier_indices)\n",
    "    outlier_pcd = cropped.select_by_index(outlier_indices)\n",
    "\n",
    "    # Color for clarity\n",
    "    inlier_pcd.paint_uniform_color([0.6, 0.6, 0.6])  # Gray\n",
    "    outlier_pcd.paint_uniform_color([1.0, 0.0, 0.0])  # Red\n",
    "\n",
    "    # Visualize together\n",
    "    o3d.visualization.draw_geometries([inlier_pcd, outlier_pcd])\n",
    "\n",
    "def visualize_dbscan_cleanup(scan_pcd, cad_mesh, x_rotation, y_rotation, z_rotation, voxel_size=1, vis_voxel_size=0.1, verbose=False):\n",
    "    #o3d.visualization.draw_geometries([scan_pcd])\n",
    "    #avg_density = estimate_point_density(scan_pcd, radius_mm=1.0, verbose=verbose)\n",
    "    cad_pcd = raycast_topdown(cad_mesh, x_rotation=x_rotation, y_rotation=y_rotation, z_rotation=z_rotation, spacing=0.1)\n",
    "    #o3d.visualization.draw_geometries([cad_pcd])\n",
    "    T_final = run_global_icp_alignment(scan_pcd, cad_pcd, voxel_size=1.0, verbose=verbose)\n",
    "    cad_pcd.paint_uniform_color([0,1,0])\n",
    "    scan_pcd.paint_uniform_color([1,0,0])\n",
    "    cad_pcd.transform(T_final)\n",
    "    cad_mesh.transform(T_final)\n",
    "    #o3d.visualization.draw_geometries([scan_pcd, cad_pcd])\n",
    "    cropped = crop_scan_near_mesh(scan_pcd, cad_mesh, max_distance=1.5)\n",
    "    cropped.paint_uniform_color([0.2, 0.35, 0.8])  # Blue for cropped points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8998eb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TriangleMesh with 2856 points and 1708 triangles."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_cloud_location = \"/home/chris/Code/PointClouds/data/FLIPscans/gratetouched.ply\"\n",
    "pcd = o3d.io.read_point_cloud(point_cloud_location)\n",
    "\n",
    "mesh = o3d.io.read_triangle_mesh(\"/home/chris/Code/PointClouds/data/FLIPscans/GrateAndCover/ventilationgrate.STL\")\n",
    "mesh.compute_vertex_normals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233088b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] RANSAC Alignment RMSE: 0.0000 | Fitness: 0.0000\n",
      "[INFO] ICP Alignment RMSE: 0.0000 | Fitness: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the point cloud\n",
    "result = preProcessData(pcd, mesh, x_rotation=0, y_rotation=0, z_rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494747d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e6ce69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointclouds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

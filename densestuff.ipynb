{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ca7716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "import open3d as o3d\n",
    "import util\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import random\n",
    "from BendLength import BendLengthCalculator\n",
    "from preprocess import preProcessData\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raycast_topdown(mesh, x_rotation, z_rotation, spacing=0.1):\n",
    "\n",
    "    x_rotation = 110\n",
    "    z_rotation = 90\n",
    "    Rx = mesh.get_rotation_matrix_from_axis_angle([np.deg2rad(x_rotation), 0, 0])\n",
    "    Rz = mesh.get_rotation_matrix_from_axis_angle([0, 0, np.deg2rad(z_rotation)])\n",
    "    mesh.rotate(Rx, center=mesh.get_center())\n",
    "    mesh.rotate(Rz, center=mesh.get_center())\n",
    "\n",
    "    scene = o3d.t.geometry.RaycastingScene()\n",
    "    t_mesh = o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n",
    "    _ = scene.add_triangles(t_mesh)\n",
    "    aabb = mesh.get_axis_aligned_bounding_box()\n",
    "    min_x, min_y, _ = aabb.min_bound\n",
    "    max_x, max_y, _ = aabb.max_bound\n",
    "    x_vals = np.linspace(min_x, max_x, int((max_x - min_x)/spacing))\n",
    "    y_vals = np.linspace(min_y, max_y, int((max_y - min_y)/spacing))\n",
    "    xx, yy = np.meshgrid(x_vals, y_vals)\n",
    "    origin_z = aabb.max_bound[2] + 10\n",
    "    origins = np.stack([xx.ravel(), yy.ravel(), np.full(xx.size, origin_z)], axis=1)\n",
    "    directions = np.tile([0, 0, -1], (len(origins), 1))\n",
    "    rays = o3d.core.Tensor(np.hstack((origins, directions)), dtype=o3d.core.Dtype.Float32)\n",
    "    hits = scene.cast_rays(rays)\n",
    "    mask = hits['t_hit'].isfinite()\n",
    "    hit_points = origins[mask.numpy()] + hits['t_hit'][mask].numpy().reshape(-1, 1) * directions[mask.numpy()]\n",
    "    return o3d.geometry.PointCloud(o3d.utility.Vector3dVector(hit_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = o3d.io.read_triangle_mesh(\"/home/chris/Code/PointClouds/data/FLIPscans/Bendy/BendyCAD.STL\")\n",
    "mesh.compute_vertex_normals()\n",
    "\n",
    "pcd = raycast_topdown(mesh, 110, 90, spacing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the point cloud\n",
    "pcd = util.preProcessSimple(pcd)\n",
    "pcd_points = np.asarray(pcd.points)\n",
    "\n",
    "# Detect planes, intersections, and anchor points\n",
    "segment_models, segments, segment_indices, main_surface_idx = util.multiOrderRansacAdvanced(pcd, pt_to_plane_dist=0.4, verbose=False, visualize=False)\n",
    "angles_rad = util.findAnglesBetweenPlanes(segment_models, main_surface_idx)\n",
    "intersection_lines = util.findIntersectionLinesLeastSquares(segment_models, main_surface_idx)\n",
    "anchor_points = util.findAnchorPoints(segment_models, segments, intersection_lines, main_surface_idx)\n",
    "\n",
    "sample_dist = 0.2\n",
    "aggregation_range = 5\n",
    "eigen_threshold = 0.07\n",
    "angle_threshold = 0.12\n",
    "radius = 1.5\n",
    "bend_length_calculator = BendLengthCalculator(pcd, anchor_points, intersection_lines, eigen_threshold, angle_threshold, aggregation_range, sample_dist, radius)\n",
    "bend_edges = bend_length_calculator.compute_bend_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d04487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating pointwise PCA using 4 workers and 16 chunks. This may take a while... (approx. 1 minute per 1M points)\n",
      "PCA calculation time: 557.69 seconds\n",
      "Calculating pointwise standard deviation. This may take a while... (approx. 30 sec per 1M points)\n",
      "Standard deviation calculation: 176.99 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate per point normal variance and 'core' points\n",
    "all_normals, pointwise_variance = util.calculatePointwiseNormalVariance(pcd, pca_radius=2, variance_radius=1.2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f3109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters found:  3\n"
     ]
    }
   ],
   "source": [
    "core_indices = util.getCorePoints(pointwise_variance)\n",
    "clusters = util.growRegionsAroundIntersections(anchor_points, core_indices, pointwise_variance, pcd_points, bend_edges, variance_percentile=62)\n",
    "print(\"Number of clusters found: \", len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b3dba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussMapVisualizer:\n",
    "    def __init__(self, pcd, all_normals, standard_deviations, clusters, radius):\n",
    "        self.pcd = pcd\n",
    "        self.points = np.asarray(pcd.points)\n",
    "        self.pcd.paint_uniform_color([0.6, 0.6, 0.6])\n",
    "        self.kdtree = cKDTree(self.points)\n",
    "        self.plane_directions = all_normals\n",
    "        self.clusters = clusters\n",
    "        self.radius = radius\n",
    "        self.standard_deviations = standard_deviations\n",
    "        low, high = np.percentile(self.standard_deviations, [60, 100])\n",
    "        self.core_indices = np.where((self.standard_deviations > low) & (self.standard_deviations <= high))[0]\n",
    "        #print(f\"Found {len(self.core_indices)} core points out of {len(self.pcd.points)} total points.\")\n",
    "        self.reference_normal = None\n",
    "        self.heatmap_mode = False  # Default mode: Bend visualization\n",
    "        self.use_global_percentile = False\n",
    "        self.current_index = 0\n",
    "        self.vis = o3d.visualization.VisualizerWithKeyCallback()\n",
    "        self.vis.create_window(\"GaussMapVisualizer\")\n",
    "        self.current_variance_percentile = 95\n",
    "\n",
    "        # **Register callback to toggle heatmap mode**\n",
    "        self.vis.register_key_callback(265, self.toggle_global_percentile)\n",
    "        self.vis.register_key_callback(263, self.toggle_heatmap)\n",
    "        self.vis.register_key_callback(262, self.next_neighborhood)\n",
    "        self.vis.register_key_callback(264, self.show_random_core_point)\n",
    "        self.vis.add_geometry(self.pcd)\n",
    "        self.apply_variation_heatmap(self.clusters)\n",
    "        self.calculate_normal_derivatives()\n",
    "        self.derivative_visible = True\n",
    "        self.vis.register_key_callback(ord(\"D\"), self.toggle_derivatives)\n",
    "        self.vis.register_key_callback(ord(\"M\"), self.increase_variance_threshold)  # Up arrow\n",
    "        self.vis.register_key_callback(ord(\"L\"), self.decrease_variance_threshold)  # Down arrow\n",
    "        self._update_neighborhood()\n",
    "\n",
    "    def toggle_derivatives(self, vis):\n",
    "        if hasattr(self, \"derivative_lines\"):\n",
    "            if self.derivative_visible:\n",
    "                self.vis.remove_geometry(self.derivative_lines)\n",
    "                print(\"Normal derivatives hidden.\")\n",
    "            else:\n",
    "                self.vis.add_geometry(self.derivative_lines)\n",
    "                print(\"Normal derivatives shown.\")\n",
    "            self.derivative_visible = not self.derivative_visible\n",
    "            vis.update_geometry(self.pcd)\n",
    "            \n",
    "    def toggle_heatmap(self, vis):\n",
    "        self.heatmap_mode = not self.heatmap_mode  # Flip mode\n",
    "        print(f'self.heatmap_mode: {self.heatmap_mode}')\n",
    "\n",
    "        if self.heatmap_mode:\n",
    "            self.apply_full_heatmap()\n",
    "            print(\"Switched to Full Point Cloud Heatmap Mode.\")\n",
    "        else:\n",
    "            self.apply_variation_heatmap(self.clusters)\n",
    "            print(\"Switched to Bends-Only Mode.\")\n",
    "\n",
    "        vis.update_geometry(self.pcd)\n",
    "        # vis.poll_events()\n",
    "        # vis.update_renderer()\n",
    "\n",
    "    def apply_full_heatmap(self):\n",
    "        \"\"\" Apply full heatmap coloring based on normal variance. \"\"\"\n",
    "        colors = self.normalize_variation_colors(self.standard_deviations)\n",
    "        self.pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    def get_nearest_neighbor_directions(self, point, kdtree, pcd, plane_directions, radius=2):\n",
    "        \"\"\" Get the directions of the k nearest neighbors to a given point. \"\"\"\n",
    "        idx = kdtree.query_ball_point(point, radius)\n",
    "        nearest_points = np.asarray(pcd.points)[idx]\n",
    "        nearest_directions = np.asarray(plane_directions)[idx]\n",
    "        return idx, nearest_points, nearest_directions\n",
    "\n",
    "    def increase_variance_threshold(self, vis):\n",
    "        self.current_variance_percentile = min(100, self.current_variance_percentile + 1)\n",
    "        print(f\"Increased threshold to {self.current_variance_percentile} percentile\")\n",
    "        self.apply_thresholded_heatmap(self.clusters)\n",
    "        vis.update_geometry(self.pcd)\n",
    "\n",
    "    def decrease_variance_threshold(self, vis):\n",
    "        self.current_variance_percentile = max(0, self.current_variance_percentile - 1)\n",
    "        print(f\"Decreased threshold to {self.current_variance_percentile} percentile\")\n",
    "        self.apply_thresholded_heatmap(self.clusters)\n",
    "        vis.update_geometry(self.pcd)\n",
    "    \n",
    "    def create_normal_lines(self, neighbor_points, neighbor_directions, scale=0.2):\n",
    "        \"\"\" Create line segments for the normal directions at each point. \"\"\"\n",
    "        line_set = o3d.geometry.LineSet()\n",
    "\n",
    "        start_points = np.array(neighbor_points)\n",
    "        end_points = start_points + scale * np.array(neighbor_directions)\n",
    "        lines = [[start_points[i], end_points[i]] for i in range(len(neighbor_points))]\n",
    "        line_set.points = o3d.utility.Vector3dVector(np.concatenate(lines, axis=0))\n",
    "        line_indices = [[i, i + 1] for i in range(0, len(lines) * 2, 2)]\n",
    "        line_set.lines = o3d.utility.Vector2iVector(line_indices)\n",
    "        line_set.colors = o3d.utility.Vector3dVector(np.tile((0, 0, 1), (len(lines), 1)))\n",
    "        return line_set\n",
    "    \n",
    "    def align_normals(self, reference_normal, neighbor_directions):\n",
    "        aligned_normals = np.array(neighbor_directions)\n",
    "        \n",
    "        # Check dot product: If negative, flip the normal\n",
    "        for i in range(len(aligned_normals)):\n",
    "            if np.dot(reference_normal, aligned_normals[i]) < 0:\n",
    "                aligned_normals[i] = -aligned_normals[i]\n",
    "\n",
    "        return aligned_normals\n",
    "    \n",
    "    def calculate_normal_variation(self, normals):\n",
    "        mu = np.mean(normals, axis=0)\n",
    "        norm = normals - mu\n",
    "        cov = np.cov(norm.T)\n",
    "        eig_val, _ = np.linalg.eig(cov)\n",
    "        sorted_idx = np.argsort(eig_val)[::-1]\n",
    "        eig_val = eig_val[sorted_idx]\n",
    "        eig_val_norm = eig_val / np.sum(eig_val)\n",
    "        \n",
    "        return mu, eig_val_norm, cov\n",
    "    \n",
    "    def update_gauss_map(self, normals):\n",
    "        \"\"\" Update the Gauss Map visualization with the current neighborhood's normals. \"\"\"\n",
    "        normals = np.array(normals)\n",
    "        normals /= np.linalg.norm(normals, axis=1, keepdims=True)  # Normalize to unit sphere\n",
    "\n",
    "        # Create figure\n",
    "        plt.figure(\"Gauss Map\", figsize=(6, 6))\n",
    "        plt.clf()  # Clear previous plot\n",
    "        ax = plt.subplot(111, projection=\"3d\")\n",
    "\n",
    "        # Plot unit sphere\n",
    "        u = np.linspace(0, 2 * np.pi, 30)\n",
    "        v = np.linspace(0, np.pi, 20)\n",
    "        x = np.outer(np.cos(u), np.sin(v))\n",
    "        y = np.outer(np.sin(u), np.sin(v))\n",
    "        z = np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "        ax.plot_surface(x, y, z, color=\"gray\", alpha=0.3, edgecolor=\"none\")  # Transparent sphere\n",
    "\n",
    "        # Plot normal vectors\n",
    "        for normal in normals:\n",
    "            ax.quiver(0, 0, 0, normal[0], normal[1], normal[2], color=\"b\", linewidth=1, arrow_length_ratio=0.1)\n",
    "\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        ax.set_zlabel(\"Z\")\n",
    "        ax.set_title(f\"Gauss Map - Neighborhood {self.current_index}\")\n",
    "\n",
    "        plt.pause(0.1)  # Allow Matplotlib to update\n",
    "\n",
    "    def show_random_core_point(self, vis):\n",
    "        if len(self.core_indices) == 0:\n",
    "            print(\"No core points found.\")\n",
    "            return\n",
    "\n",
    "        # Pick a random core point\n",
    "        self.current_index = random.choice(self.core_indices)\n",
    "\n",
    "        # Visualize its neighborhood\n",
    "        self._update_neighborhood()\n",
    "\n",
    "        print(f\"Showing core point {self.current_index}.\")\n",
    "\n",
    "    def compute_normal_derivative_pca(self, normals):\n",
    "        \"\"\"Compute dominant direction of normal variation using PCA.\"\"\"\n",
    "        cov = np.cov(normals.T)\n",
    "        eig_vals, eig_vecs = np.linalg.eigh(cov)\n",
    "        return eig_vecs[:, np.argmax(eig_vals)]  # Largest eigenvector = main change direction\n",
    "    \n",
    "    def calculate_normal_derivatives(self):\n",
    "        \"\"\"Compute normal derivatives for all core points and store them for visualization.\"\"\"\n",
    "        self.derivative_vectors = []\n",
    "        self.derivative_positions = []\n",
    "\n",
    "        for i, core_idx in enumerate(self.core_indices):\n",
    "            # Get neighborhood\n",
    "            print(f\"Computing normal derivative {i}/{len(self.core_indices)}\")\n",
    "            core_point = self.points[core_idx]\n",
    "            neighbor_indices = self.kdtree.query_ball_point(core_point, self.radius)\n",
    "\n",
    "            if len(neighbor_indices) < 3:\n",
    "                continue  # Skip small neighborhoods\n",
    "\n",
    "            neighbors = self.points[neighbor_indices]\n",
    "            normals = self.plane_directions[neighbor_indices]\n",
    "\n",
    "            # Compute normal derivative\n",
    "            normal_gradient = self.compute_normal_derivative_pca(normals)  # or self.compute_normal_derivative\n",
    "\n",
    "            self.derivative_positions.append(core_point)\n",
    "            self.derivative_vectors.append(normal_gradient)\n",
    "\n",
    "        print(f\"Computed {len(self.derivative_vectors)} normal derivatives.\")\n",
    "        self.add_normal_derivatives()\n",
    "\n",
    "    def add_normal_derivatives(self):\n",
    "        \"\"\"Add the precomputed normal derivative vectors to the visualization.\"\"\"\n",
    "        if self.derivative_vectors:\n",
    "            self.derivative_lines = self.create_lines(self.derivative_positions, self.derivative_vectors, color=(1, 0, 0), scale=1.5)\n",
    "            self.vis.add_geometry(self.derivative_lines)\n",
    "            print(f\"Added {len(self.derivative_vectors)} normal derivative vectors to the visualization.\")\n",
    "\n",
    "    def _update_neighborhood(self):\n",
    "        \"\"\" Update visualization for the current neighborhood. \"\"\"\n",
    "        # Get the currently selected point\n",
    "        query_point = np.asarray(self.pcd.points)[self.current_index]\n",
    "\n",
    "        # Get nearest neighbors\n",
    "        idx, neighbor_points, neighbor_directions = self.get_nearest_neighbor_directions(query_point, self.kdtree, self.pcd, self.plane_directions, radius=self.radius)\n",
    "        if self.current_index==0:\n",
    "            self.reference_normal = neighbor_directions[0]\n",
    "\n",
    "        aligned_directions = self.align_normals(self.reference_normal, neighbor_directions)\n",
    "        normal_mean, normal_variation, cov_after = self.calculate_normal_variation(aligned_directions)\n",
    "\n",
    "        if hasattr(self, \"normal_lines\"):\n",
    "            self.vis.remove_geometry(self.normal_lines)\n",
    "        self.normal_lines = self.create_normal_lines(neighbor_points, aligned_directions, scale=2)\n",
    "        self.vis.add_geometry(self.normal_lines)\n",
    "        view_ctl = self.vis.get_view_control()\n",
    "        lookat = query_point\n",
    "        zoom = 0.080000000000000002\n",
    "        front = [-0.024106890455448116,-0.57254772319971181,0.81951690799604338]\n",
    "        up =  [0.014828165865396817,0.81946017828866602,0.57294427451208185]\n",
    "        view_ctl.set_lookat(lookat)  # Set the point the camera is looking at\n",
    "        view_ctl.set_up(up)      # Set the up direction of the camera\n",
    "        view_ctl.set_front(front)  # Set the front direction of the camera\n",
    "        view_ctl.set_zoom(zoom)          # Set the zoom factor of the camera\n",
    "\n",
    "        self.update_gauss_map(aligned_directions)\n",
    "\n",
    "        self.vis.update_geometry(self.pcd)\n",
    "        print(f\"Neighborhood {self.current_index}/{len(self.pcd.points)} updated\", flush=True)\n",
    "        #print(f'Aligned normals: {neighbor_directions}', flush=True)\n",
    "        #print(f\"Normal mean: {normal_mean}, Normal variation: {normal_variation}\", flush=True)\n",
    "        #print(f\"Std Dev of Normals: {np.std(neighbor_directions, axis=0)}\")\n",
    "        #print(f\"Condition Number of Covariance: {np.linalg.cond(cov_after)}\")\n",
    "        print(15*\"-\", flush=True)\n",
    "\n",
    "    def next_neighborhood(self, vis):\n",
    "        \"\"\" Move to the next neighborhood when right arrow key is pressed. \"\"\"\n",
    "        self.current_index = (self.current_index + 500) % len(self.pcd.points)\n",
    "        self._update_neighborhood()\n",
    "    \n",
    "    def normalize_variation_colors(self, variation_values, use_global=False):\n",
    "        \"\"\" \n",
    "        Normalize variation values to a colormap range.\n",
    "        \n",
    "        Args:\n",
    "            variation_values (np.ndarray): The normal variance values.\n",
    "            use_global (bool): Whether to use global percentile normalization.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: RGB colors mapped from a colormap.\n",
    "        \"\"\"\n",
    "        if use_global:\n",
    "            min_val, max_val = np.percentile(self.standard_deviations, [2, 98])  # Use all points\n",
    "        else:\n",
    "            min_val, max_val = np.percentile(variation_values, [2, 98])  # Use local cluster\n",
    "\n",
    "        norm_variation = (variation_values - min_val) / (max_val - min_val + 1e-6)  # Normalize to [0,1]\n",
    "        colors = cm.viridis(np.clip(norm_variation, 0, 1))[:, :3]  # Extract RGB colors\n",
    "\n",
    "        return colors\n",
    "    \n",
    "    def toggle_global_percentile(self, vis):\n",
    "        \"\"\" Toggle between local and global percentile normalization. \"\"\"\n",
    "        self.use_global_percentile = not self.use_global_percentile  # Flip mode\n",
    "        self.apply_variation_heatmap(self.clusters)  # Reapply colors\n",
    "\n",
    "        mode = \"Global\" if self.use_global_percentile else \"Local\"\n",
    "        print(f\"Switched to {mode} Percentile Normalization.\")\n",
    "\n",
    "        vis.update_geometry(self.pcd)\n",
    "\n",
    "    def create_lines(self, points, vectors, color=(1, 0, 0), scale=1.0):\n",
    "        \"\"\"Creates Open3D line geometry for visualization.\"\"\"\n",
    "        start_points = np.array(points)\n",
    "        end_points = start_points + scale * np.array(vectors)\n",
    "        line_set = o3d.geometry.LineSet()\n",
    "        line_set.points = o3d.utility.Vector3dVector(np.vstack((start_points, end_points)))\n",
    "        line_indices = [[i, i + len(points)] for i in range(len(points))]\n",
    "        line_set.lines = o3d.utility.Vector2iVector(line_indices)\n",
    "        line_set.colors = o3d.utility.Vector3dVector([color] * len(line_indices))\n",
    "        return line_set\n",
    "    \n",
    "    def apply_variation_heatmap(self, clusters, unclustered_color=(0.7, 0.7, 0.7)):\n",
    "        \"\"\"\n",
    "        Colors clustered points using the heatmap and assigns a uniform color to unclustered points.\n",
    "\n",
    "        Args:\n",
    "            clusters (list of sets): List of clusters, where each set contains indices of points in a cluster.\n",
    "            unclustered_color (tuple): RGB color for unclustered points (default: light gray).\n",
    "        \"\"\"\n",
    "        num_points = len(self.points)\n",
    "        colors = np.full((num_points, 3), fill_value=unclustered_color)  # Default: all points = light gray\n",
    "\n",
    "        clustered_indices = np.array([idx for cluster in clusters.values() for idx in cluster])\n",
    "\n",
    "        if clustered_indices.size > 0:\n",
    "            clustered_variance = self.standard_deviations[clustered_indices]\n",
    "\n",
    "            # **Use global or local percentile normalization**\n",
    "            clustered_colors = self.normalize_variation_colors(clustered_variance, use_global=self.use_global_percentile)\n",
    "\n",
    "            # **Apply heatmap colors to clustered points**\n",
    "            colors[clustered_indices] = clustered_colors  \n",
    "\n",
    "        self.pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        mode = \"Global\" if self.use_global_percentile else \"Local\"\n",
    "        print(f\"Applied {mode} Percentile Heatmap to Clusters.\")\n",
    "\n",
    "    def apply_thresholded_heatmap(self, clusters, unclustered_color=(0.7, 0.7, 0.7)):\n",
    "        num_points = len(self.points)\n",
    "        colors = np.full((num_points, 3), fill_value=unclustered_color)\n",
    "\n",
    "        clustered_indices = np.array([idx for cluster in clusters.values() for idx in cluster])\n",
    "\n",
    "        if clustered_indices.size > 0:\n",
    "            clustered_variance = self.standard_deviations[clustered_indices]\n",
    "\n",
    "            # Threshold based on selected percentile\n",
    "            threshold = np.percentile(clustered_variance, self.current_variance_percentile)\n",
    "            keep_mask = clustered_variance >= threshold\n",
    "            kept_indices = clustered_indices[keep_mask]\n",
    "            kept_variance = clustered_variance[keep_mask]\n",
    "\n",
    "            # Color only the high-variance points\n",
    "            kept_colors = self.normalize_variation_colors(kept_variance, use_global=self.use_global_percentile)\n",
    "            colors[kept_indices] = kept_colors\n",
    "\n",
    "        self.pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        print(f\"Applied variance threshold at {self.current_variance_percentile}th percentile\")\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.vis.run()  # Start the visualization loop (blocks until closed)\n",
    "        self.vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f993f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = GaussMapVisualizer(pcd, all_normals, pointwise_variance, clusters, radius=2)\n",
    "#visualizer.apply_variation_heatmap(clusters)  # Apply cluster + heatmap visualization\n",
    "visualizer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6265ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cluster_derivatives = {}\n",
    "bend_data = {}\n",
    "\n",
    "for cluster_id, cluster in clusters.items():\n",
    "    cluster_indices = np.array([idx for idx in cluster])\n",
    "    points = pcd_points[cluster_indices]\n",
    "    print(f'Cluster {cluster_id} - length of points: {len(cluster_indices)}')\n",
    "\n",
    "    normals = all_normals[cluster_indices]\n",
    "    derivatives = util.calculate_normal_derivatives(normals, points, radius=2, verbose=False)\n",
    "\n",
    "    cluster_derivatives[cluster_id] = derivatives\n",
    "\n",
    "    if cluster_id in intersection_lines and cluster_id in bend_edges:\n",
    "        bend_data[cluster_id] = {\n",
    "            \"intersection_line\": intersection_lines[cluster_id],\n",
    "            \"bend_edges\": bend_edges[cluster_id],\n",
    "            \"cluster_points\": points,\n",
    "            \"cluster_derivatives\": derivatives,\n",
    "            \"anchor_points\": anchor_points[cluster_id],\n",
    "        }\n",
    "\n",
    "# Final output to pickle\n",
    "with open(\"/home/chris/Code/PointClouds/data/temp_data/bend_visualization_data_dense.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"pcd_points\": np.asarray(pcd.points),\n",
    "        \"bend_data\": bend_data,\n",
    "        \"all_normals\": all_normals,\n",
    "        \"segment_indices\": segment_indices,\n",
    "        \"segment_models\": segment_models,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895eac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.asarray(pcd.points)))\n",
    "print(len(all_normals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointclouds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
